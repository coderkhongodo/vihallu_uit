#!/usr/bin/env python3
"""
Multi-Agent Debate V6 - KEYWORD OPTIMIZED

CHIáº¾N LÆ¯á»¢C:
- GIá»® NGUYÃŠN cáº¥u trÃºc V6 Final (Ä‘Ã£ tá»‘t: 0.7462)
- CHá»ˆ THAY tá»« khÃ³a: "MÃ‚U THUáºªN" â†’ "TRÃI NGÆ¯á»¢C", "PHá»¦ Äá»ŠNH" â†’ "Äáº¢O NGÆ¯á»¢C"
- THÃŠM 1 vÃ­ dá»¥ CONTRAST rÃµ rÃ ng
- Há»c tá»« English prompts (intrinsic 59.46%) nhÆ°ng giá»¯ cáº¥u trÃºc Vietnamese

TARGET: Macro-F1 > 0.75, intrinsic recall > 58%, extrinsic recall > 85%
"""

import argparse
import sys
import json
import re
from pathlib import Path
from typing import Tuple

import pandas as pd
import torch
from tqdm import tqdm
from transformers import AutoModelForCausalLM, AutoTokenizer
from sklearn.metrics import (
    accuracy_score,
    precision_recall_fscore_support,
    confusion_matrix,
)

# AGENT 1: Accuser - KEYWORD OPTIMIZED
AGENT1_SYSTEM_PROMPT = """Báº¡n lÃ  Agent 1 (NgÆ°á»i buá»™c tá»™i) trong há»‡ thá»‘ng tranh luáº­n phÃ¡t hiá»‡n hallucination.

NHIá»†M Vá»¤: PhÃ¢n tÃ­ch cÃ¢u tráº£ lá»i vÃ  xÃ¡c Ä‘á»‹nh loáº¡i hallucination (náº¿u cÃ³).

âš ï¸ PHÃ‚N BIá»†T QUAN TRá»ŒNG (Äá»ŒC Ká»¸):

**intrinsic (TRÃI NGÆ¯á»¢C - Äáº¢O NGÆ¯á»¢C)**:
- Response TRÃI NGÆ¯á»¢C / Äáº¢O NGÆ¯á»¢C / BÃ“P MÃ‰O thÃ´ng tin trong Context
- VD1: Context: "MÃ¨o Ä‘en" â†’ Response: "MÃ¨o tráº¯ng" = intrinsic (Ä‘en â‰  tráº¯ng, Äáº¢O NGÆ¯á»¢C mÃ u)
- VD2: Context: "Ão dÃ i máº·c bá»Ÿi ná»¯" â†’ Response: "Ão dÃ i CHá»ˆ máº·c bá»Ÿi nam" = intrinsic (Äáº¢O NGÆ¯á»¢C giá»›i tÃ­nh)
- VD3: Context: "X gÃ¢y ra Y" â†’ Response: "Z gÃ¢y ra Y" = intrinsic (Äáº¢O NGÆ¯á»¢C nguyÃªn nhÃ¢n)
- **QUAN TRá»ŒNG**: ÄÃ¢y lÃ  Äáº¢O NGÆ¯á»¢C thÃ´ng tin cÃ³ sáºµn, KHÃ”NG pháº£i thÃªm thÃ´ng tin!

**extrinsic (THÃŠM thÃ´ng tin Má»šI - KHÃ”NG trÃ¡i ngÆ°á»£c)**:
- Response THÃŠM thÃ´ng tin HOÃ€N TOÃ€N Má»šI mÃ  Context khÃ´ng Ä‘á» cáº­p
- VD1: Context: "MÃ¨o Ä‘en" â†’ Response: "MÃ¨o Ä‘en vÃ  thÃ¢n thiá»‡n" = extrinsic (THÃŠM "thÃ¢n thiá»‡n")
- VD2: Context: "Ão dÃ i truyá»n thá»‘ng" â†’ Response: "Ão dÃ i cÃ³ 5 mÃ u" = extrinsic (THÃŠM "5 mÃ u")
- **QUAN TRá»ŒNG**: ÄÃ¢y lÃ  THÃŠM info má»›i, KHÃ”NG Ä‘áº£o ngÆ°á»£c info cÅ©!

**no (TRUNG THá»°C)**:
- Response Ä‘Æ°á»£c há»— trá»£ hoÃ n toÃ n bá»Ÿi Context
- Diá»…n Ä‘áº¡t láº¡i hoáº·c suy luáº­n há»£p lÃ½ = no

ğŸ”´ PHÃ‚N BIá»†T RÃ• RÃ€NG (Há»ŒC Ká»¸):
- **TRÃI NGÆ¯á»¢C** (intrinsic): Äen â†’ Tráº¯ng (Äáº¢O NGÆ¯á»¢C mÃ u)
- **THÃŠM** (extrinsic): Äen â†’ Äen + thÃ¢n thiá»‡n (THÃŠM tÃ­nh cÃ¡ch)
- **DIá»„N Äáº T** (no): Äen â†’ CÃ³ mÃ u Ä‘en (DIá»„N Äáº T láº¡i)

ğŸ”´ Cáº¢NH BÃO - Äá»ªNG NHáº¦M LáºªN:
- âŒ SAI: "MÃ¨o Ä‘en" â†’ "MÃ¨o tráº¯ng" = extrinsic (thÃªm mÃ u tráº¯ng)
- âœ… ÄÃšNG: "MÃ¨o Ä‘en" â†’ "MÃ¨o tráº¯ng" = intrinsic (TRÃI NGÆ¯á»¢C mÃ u Ä‘en)

- âŒ SAI: "Ão dÃ i máº·c bá»Ÿi ná»¯" â†’ "Ão dÃ i chá»‰ máº·c bá»Ÿi nam" = extrinsic
- âœ… ÄÃšNG: "Ão dÃ i máº·c bá»Ÿi ná»¯" â†’ "Ão dÃ i chá»‰ máº·c bá»Ÿi nam" = intrinsic (TRÃI NGÆ¯á»¢C giá»›i tÃ­nh)

QUY TRÃŒNH PHÃ‚N TÃCH:
1. TÃ¬m TRÃI NGÆ¯á»¢C trÆ°á»›c tiÃªn (Æ°u tiÃªn cao nháº¥t)
   - Response cÃ³ Äáº¢O NGÆ¯á»¢C Context khÃ´ng?
   - CÃ³ TRÃI NGÆ¯á»¢C thÃ´ng tin trong Context khÃ´ng?
2. Náº¿u CÃ“ trÃ¡i ngÆ°á»£c â†’ intrinsic (Dá»ªNG, khÃ´ng xÃ©t tiáº¿p)
3. Náº¿u KHÃ”NG cÃ³ trÃ¡i ngÆ°á»£c:
   - Response cÃ³ THÃŠM info má»›i khÃ´ng? â†’ Kiá»ƒm tra Ká»¸ tá»«ng thÃ´ng tin â†’ extrinsic
   - Response chá»‰ diá»…n Ä‘áº¡t láº¡i? â†’ no

FORMAT Äáº¦U RA (Báº®T BUá»˜C):
```
PhÃ¢n tÃ­ch: <kiá»ƒm tra trÃ¡i ngÆ°á»£c trÆ°á»›c, sau Ä‘Ã³ kiá»ƒm tra ká»¹ bá»• sung thÃ´ng tin>
NhÃ£n: <no HOáº¶C intrinsic HOáº¶C extrinsic>
```

LÆ¯U Ã: Náº¿u tháº¥y TRÃI NGÆ¯á»¢C / Äáº¢O NGÆ¯á»¢C, pháº£i chá»n "intrinsic", KHÃ”NG Ä‘Æ°á»£c chá»n "extrinsic"!
"""

# AGENT 2: Defender - KEYWORD OPTIMIZED
AGENT2_SYSTEM_PROMPT = """Báº¡n lÃ  Agent 2 (NgÆ°á»i báº£o vá»‡) trong há»‡ thá»‘ng tranh luáº­n phÃ¡t hiá»‡n hallucination.

NHIá»†M Vá»¤: Kiá»ƒm tra láº¡i phÃ¢n tÃ­ch cá»§a Agent 1 má»™t cÃ¡ch KHÃCH QUAN.

âš ï¸ VAI TRÃ’ QUAN TRá»ŒNG:
- KHÃ”NG báº£o vá»‡ mÃ¹ quÃ¡ng
- Náº¿u Agent 1 ÄÃšNG â†’ thá»«a nháº­n
- Náº¿u Agent 1 SAI â†’ chá»‰ ra sai láº§m vá»›i báº±ng chá»©ng tá»« Context

ğŸ” KIá»‚M TRA Äáº¶C BIá»†T - Nháº§m láº«n intrinsic/extrinsic:

**Náº¿u Agent 1 nÃ³i "extrinsic" nhÆ°ng cÃ³ TRÃI NGÆ¯á»¢C**:
- Kiá»ƒm tra: Response cÃ³ TRÃI NGÆ¯á»¢C / Äáº¢O NGÆ¯á»¢C Context khÃ´ng?
- Náº¿u CÃ“ â†’ ÄÃ¢y lÃ  intrinsic, KHÃ”NG pháº£i extrinsic!
- VD: Context "MÃ¨o Ä‘en" â†’ Response "MÃ¨o tráº¯ng" = intrinsic (trÃ¡i ngÆ°á»£c), khÃ´ng pháº£i extrinsic

**Náº¿u Agent 1 nÃ³i "intrinsic" nhÆ°ng KHÃ”NG cÃ³ trÃ¡i ngÆ°á»£c**:
- Kiá»ƒm tra: Response cÃ³ thá»±c sá»± TRÃI NGÆ¯á»¢C Context khÃ´ng?
- Náº¿u chá»‰ THÃŠM info má»›i â†’ ÄÃ¢y lÃ  extrinsic, khÃ´ng pháº£i intrinsic!
- VD: Context "MÃ¨o Ä‘en" â†’ Response "MÃ¨o Ä‘en vÃ  thÃ¢n thiá»‡n" = extrinsic (thÃªm info), khÃ´ng pháº£i intrinsic

**ğŸ†• Náº¿u Agent 1 nÃ³i "no" - KIá»‚M TRA Ká»¸ EXTRINSIC**:
- Liá»‡t kÃª Tá»ªNG thÃ´ng tin trong Response
- Check tá»«ng thÃ´ng tin: CÃ³ trong Context khÃ´ng?
- Náº¿u cÃ³ thÃ´ng tin KHÃ”NG CÃ“ trong Context â†’ ÄÃ¢y lÃ  extrinsic, khÃ´ng pháº£i no!
- VD: Context "Malaysia Ä‘a dÃ¢n tá»™c" â†’ Response "Malaysia Ä‘a dÃ¢n tá»™c vÃ  cÃ³ ná»n kinh táº¿ phÃ¡t triá»ƒn"
  * "Ä‘a dÃ¢n tá»™c" âœ“ cÃ³
  * "ná»n kinh táº¿ phÃ¡t triá»ƒn" âœ— KHÃ”NG cÃ³ â†’ extrinsic

Äá»ŠNH NGHÄ¨A:
- **intrinsic**: Response TRÃI NGÆ¯á»¢C / Äáº¢O NGÆ¯á»¢C Context
- **extrinsic**: Response THÃŠM info Má»šI (khÃ´ng trÃ¡i ngÆ°á»£c)
- **no**: Response Ä‘Æ°á»£c há»— trá»£ hoÃ n toÃ n

QUY TRÃŒNH:
1. Äá»c phÃ¢n tÃ­ch cá»§a Agent 1
2. Kiá»ƒm tra láº¡i vá»›i Context
3. Náº¿u Agent 1 Ä‘Ãºng â†’ thá»«a nháº­n vÃ  giáº£i thÃ­ch táº¡i sao
4. Náº¿u Agent 1 sai â†’ chá»‰ ra sai láº§m vÃ  Ä‘Æ°a ra phÃ¢n loáº¡i Ä‘Ãºng

FORMAT Äáº¦U RA (Báº®T BUá»˜C):
```
ÄÃ¡nh giÃ¡ Agent 1: <Ä‘Ãºng hay sai, táº¡i sao>
PhÃ¢n tÃ­ch cá»§a tÃ´i: <phÃ¢n tÃ­ch khÃ¡ch quan, Ä‘áº·c biá»‡t chÃº Ã½ extrinsic>
NhÃ£n: <no HOáº¶C intrinsic HOáº¶C extrinsic>
```

LÆ¯U Ã: Æ¯u tiÃªn sá»± tháº­t hÆ¡n lÃ  báº£o vá»‡ Response! Äáº·c biá»‡t chÃº Ã½ kiá»ƒm tra extrinsic!
"""

# AGENT 3: Judge - KEYWORD OPTIMIZED
AGENT3_SYSTEM_PROMPT = """Báº¡n lÃ  Agent 3 (Tháº©m phÃ¡n) trong há»‡ thá»‘ng tranh luáº­n phÃ¡t hiá»‡n hallucination.

NHIá»†M Vá»¤: ÄÆ°a ra phÃ¡n quyáº¿t CUá»I CÃ™NG dá»±a trÃªn phÃ¢n tÃ­ch cá»§a Agent 1 vÃ  Agent 2.

ğŸš¨ QUY Táº®C Æ¯U TIÃŠN NGHIÃŠM NGáº¶T (TUÃ‚N THá»¦ Báº®T BUá»˜C):

**BÆ¯á»šC 1: Kiá»ƒm tra TRÃI NGÆ¯á»¢C (Æ°u tiÃªn cao nháº¥t)**
- Response cÃ³ TRÃI NGÆ¯á»¢C / Äáº¢O NGÆ¯á»¢C thÃ´ng tin trong Context khÃ´ng?
- CÃ³ thay Ä‘á»•i Ã½ nghÄ©a tá»« A thÃ nh KHÃ”NG-A khÃ´ng?
- VD: "Ä‘en" â†’ "tráº¯ng", "ná»¯" â†’ "nam", "X" â†’ "Z"

**Náº¿u CÃ“ TRÃI NGÆ¯á»¢C â†’ intrinsic (Dá»ªNG NGAY, khÃ´ng xÃ©t bÆ°á»›c 2)**

**BÆ¯á»šC 2: Kiá»ƒm tra THÃŠM thÃ´ng tin (chá»‰ khi KHÃ”NG cÃ³ trÃ¡i ngÆ°á»£c)**
- Response cÃ³ THÃŠM info HOÃ€N TOÃ€N Má»šI khÃ´ng?
- Info nÃ y cÃ³ trong Context khÃ´ng?

**Náº¿u THÃŠM info má»›i â†’ extrinsic**
**Náº¿u chá»‰ diá»…n Ä‘áº¡t láº¡i â†’ no**

âš ï¸ Cáº¢NH BÃO QUAN TRá»ŒNG - Äá»ªNG NHáº¦M LáºªN:

**TRÃI NGÆ¯á»¢C â‰  THÃŠM THÃ”NG TIN**
- TRÃI NGÆ¯á»¢C = Äáº¢O NGÆ¯á»¢C thÃ´ng tin cÃ³ sáºµn = intrinsic
- THÃŠM info = THÃŠM thÃ´ng tin má»›i = extrinsic
- ÄÃ¢y lÃ  HAI KHÃI NIá»†M KHÃC NHAU!

ğŸ”´ PHÃ‚N BIá»†T RÃ• RÃ€NG:
- **TRÃI NGÆ¯á»¢C** (intrinsic): Äen â†’ Tráº¯ng (Äáº¢O NGÆ¯á»¢C mÃ u)
- **THÃŠM** (extrinsic): Äen â†’ Äen + thÃ¢n thiá»‡n (THÃŠM tÃ­nh cÃ¡ch)
- **DIá»„N Äáº T** (no): Äen â†’ CÃ³ mÃ u Ä‘en (DIá»„N Äáº T láº¡i)

ğŸ”´ PHáº¢N VÃ Dá»¤ (Há»c tá»« lá»—i):

âŒ **SAI**:
- Context: "MÃ¨o Ä‘en" â†’ Response: "MÃ¨o tráº¯ng"
- Suy nghÄ© sai: "Response thÃªm mÃ u tráº¯ng â†’ extrinsic"
- âœ… **ÄÃšNG**: "Response TRÃI NGÆ¯á»¢C mÃ u Ä‘en â†’ intrinsic"

âŒ **SAI**:
- Context: "Ão dÃ i máº·c bá»Ÿi ná»¯" â†’ Response: "Ão dÃ i chá»‰ máº·c bá»Ÿi nam"
- Suy nghÄ© sai: "Response thÃªm thÃ´ng tin vá» nam â†’ extrinsic"
- âœ… **ÄÃšNG**: "Response TRÃI NGÆ¯á»¢C thÃ´ng tin vá» ná»¯ â†’ intrinsic"

âœ… **ÄÃšNG** (extrinsic thá»±c sá»±):
- Context: "MÃ¨o Ä‘en" â†’ Response: "MÃ¨o Ä‘en vÃ  thÃ¢n thiá»‡n"
- KhÃ´ng cÃ³ trÃ¡i ngÆ°á»£c, chá»‰ THÃŠM "thÃ¢n thiá»‡n" â†’ extrinsic

ğŸ†• **Äáº¶C BIá»†T CHÃš Ã - CÃ‚N Báº°NG EXTRINSIC**:
- Náº¿u Agent 2 chá»‰ ra cÃ³ bá»• sung thÃ´ng tin cá»¥ thá»ƒ â†’ Xem xÃ©t nghiÃªm tÃºc
- KHÃ”NG bá» qua extrinsic chá»‰ vÃ¬ Æ°u tiÃªn intrinsic
- Kiá»ƒm tra ká»¹: CÃ³ thá»±c sá»± bá»• sung thÃ´ng tin má»›i khÃ´ng?

QUY TRÃŒNH PHÃN QUYáº¾T:
1. Äá»c phÃ¢n tÃ­ch cá»§a Agent 1 vÃ  Agent 2
2. **BÆ¯á»šC 1**: Kiá»ƒm tra TRÃI NGÆ¯á»¢C
   - Náº¿u CÃ“ â†’ intrinsic (Dá»ªNG)
3. **BÆ¯á»šC 2**: Náº¿u KHÃ”NG cÃ³ trÃ¡i ngÆ°á»£c
   - Kiá»ƒm tra Ká»¸ LÆ¯á» NG THÃŠM info â†’ extrinsic hoáº·c no
4. ÄÆ°a ra phÃ¡n quyáº¿t cuá»‘i cÃ¹ng

FORMAT Äáº¦U RA (Cá»°C Ká»² QUAN TRá»ŒNG):
```
Kiá»ƒm tra trÃ¡i ngÆ°á»£c: <CÃ“ hay KHÃ”NG, náº¿u cÃ³ thÃ¬ trÃ¡i ngÆ°á»£c gÃ¬>
Náº¿u khÃ´ng cÃ³ trÃ¡i ngÆ°á»£c, kiá»ƒm tra thÃªm info: <cÃ³ thÃªm info gÃ¬ khÃ´ng>
LÃ½ do cuá»‘i cÃ¹ng: <giáº£i thÃ­ch táº¡i sao chá»n nhÃ£n nÃ y>
NhÃ£n cuá»‘i cÃ¹ng: <no HOáº¶C intrinsic HOáº¶C extrinsic>
```

ğŸš¨ NHáº®C NHá» CUá»I CÃ™NG:
- Náº¿u tháº¥y TRÃI NGÆ¯á»¢C / Äáº¢O NGÆ¯á»¢C â†’ PHáº¢I chá»n "intrinsic"
- Äá»ªNG chá»n "extrinsic" khi cÃ³ trÃ¡i ngÆ°á»£c!
- TRÃI NGÆ¯á»¢C = intrinsic, THÃŠM info = extrinsic
- KHÃ”NG bá» qua extrinsic khi cÃ³ báº±ng chá»©ng rÃµ rÃ ng!
"""


def parse_label_v6(text: str) -> str:
    """Enhanced label parsing for V6."""
    if not text:
        return "other"
    
    text_lower = text.lower()
    
    # Priority 1: Vietnamese label patterns
    patterns = [
        r'nhÃ£n\s*cuá»‘i\s*cÃ¹ng\s*[:ï¼š]\s*(no|intrinsic|extrinsic)',
        r'nhÃ£n\s*[:ï¼š]\s*(no|intrinsic|extrinsic)',
        r'label\s*[:ï¼š]\s*["\']?\s*(no|intrinsic|extrinsic)',
    ]
    
    for pattern in patterns:
        m = re.search(pattern, text_lower)
        if m:
            return m.group(1)
    
    # Priority 2: Last occurrence
    matches = list(re.finditer(r'\b(no|intrinsic|extrinsic)\b', text_lower))
    if matches:
        return matches[-1].group(1)
    
    # Priority 3: Check for faithful
    if re.search(r'\b(faithful|trung\s*thá»±c)\b', text_lower):
        return "no"
    
    return "other"


def generate_agent_response(
    model,
    tokenizer,
    system_prompt: str,
    user_message: str,
    max_new_tokens: int = 300,
    temperature: float = 0.15,
) -> str:
    """Generate response with optimized parameters."""
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_message}
    ]
    
    input_text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True
    )
    
    inputs = tokenizer(
        input_text,
        return_tensors="pt",
        truncation=True,
        max_length=2048
    ).to(model.device)
    
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=max_new_tokens,
            temperature=temperature,
            do_sample=temperature > 0,
            pad_token_id=tokenizer.pad_token_id,
            eos_token_id=tokenizer.eos_token_id,
        )
    
    generated_text = tokenizer.decode(
        outputs[0][inputs['input_ids'].shape[1]:], 
        skip_special_tokens=True
    )
    
    return generated_text


def debate_prediction_v6(
    model,
    tokenizer,
    context: str,
    prompt: str,
    response: str,
    max_new_tokens: int = 300,
    temperature: float = 0.15,
) -> Tuple[str, str, str, str]:
    """Run V6 improved debate."""
    
    # Agent 1: Accuser
    agent1_message = f"""Ngá»¯ cáº£nh: {context}

CÃ¢u há»i: {prompt}

CÃ¢u tráº£ lá»i: {response}

PhÃ¢n tÃ­ch cÃ¢u tráº£ lá»i nÃ y. Kiá»ƒm tra MÃ‚U THUáºªN trÆ°á»›c, sau Ä‘Ã³ kiá»ƒm tra THÃŠM thÃ´ng tin."""

    agent1_output = generate_agent_response(
        model, tokenizer, AGENT1_SYSTEM_PROMPT, agent1_message,
        max_new_tokens, temperature
    )
    
    # Agent 2: Defender
    agent2_message = f"""Ngá»¯ cáº£nh: {context}

CÃ¢u há»i: {prompt}

CÃ¢u tráº£ lá»i: {response}

PhÃ¢n tÃ­ch cá»§a Agent 1: {agent1_output}

Kiá»ƒm tra láº¡i phÃ¢n tÃ­ch cá»§a Agent 1 má»™t cÃ¡ch khÃ¡ch quan. Äáº·c biá»‡t chÃº Ã½: Agent 1 cÃ³ nháº§m láº«n giá»¯a intrinsic vÃ  extrinsic khÃ´ng?"""

    agent2_output = generate_agent_response(
        model, tokenizer, AGENT2_SYSTEM_PROMPT, agent2_message,
        max_new_tokens, temperature
    )
    
    # Agent 3: Judge (very low temperature for consistency)
    agent3_message = f"""Ngá»¯ cáº£nh: {context}

CÃ¢u há»i: {prompt}

CÃ¢u tráº£ lá»i: {response}

PhÃ¢n tÃ­ch cá»§a Agent 1: {agent1_output}

PhÃ¢n tÃ­ch cá»§a Agent 2: {agent2_output}

ÄÆ°a ra phÃ¡n quyáº¿t cuá»‘i cÃ¹ng. QUAN TRá»ŒNG: Kiá»ƒm tra MÃ‚U THUáºªN trÆ°á»›c. Náº¿u cÃ³ mÃ¢u thuáº«n â†’ intrinsic (Dá»ªNG)."""

    judge_temperature = 0.1  # Very low for strict priority enforcement
    agent3_output = generate_agent_response(
        model, tokenizer, AGENT3_SYSTEM_PROMPT, agent3_message,
        max_new_tokens, judge_temperature
    )
    
    final_label = parse_label_v6(agent3_output)
    
    return agent1_output, agent2_output, agent3_output, final_label


def normalize_label(label: str) -> str:
    """Normalize label."""
    label = str(label).strip().lower()
    if label == "faithful":
        return "no"
    if label in ["no", "intrinsic", "extrinsic"]:
        return label
    return "other"


def evaluate_multi_agent_debate_v6(
    model_path: str,
    test_csv: str,
    output_dir: str = "debate_v6_results",
    max_samples: int = 100,
    max_new_tokens: int = 300,
    temperature: float = 0.15,
):
    """Evaluate V6 improved debate."""
    print(f"\n{'='*70}")
    print(f"MULTI-AGENT DEBATE V6 - IMPROVED PROMPTS")
    print(f"{'='*70}")
    print(f"Model: {model_path}")
    print(f"Test data: {test_csv}")
    print(f"Max samples: {max_samples}")
    print(f"Max tokens: {max_new_tokens}")
    print(f"Temperature: {temperature}")
    print(f"{'='*70}\n")

    # Load model
    print("Loading model...")
    model = AutoModelForCausalLM.from_pretrained(
        model_path,
        torch_dtype=torch.float16,
        device_map="auto",
        trust_remote_code=True,
    )

    tokenizer = AutoTokenizer.from_pretrained(
        model_path,
        trust_remote_code=True,
    )

    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token

    model.eval()
    print("âœ“ Model loaded\n")

    # Load data
    df = pd.read_csv(test_csv)
    df = df.head(max_samples)
    df['label_normalized'] = df['label'].apply(normalize_label)

    print(f"Evaluating {len(df)} samples")
    print("Ground truth:")
    for label, count in df['label_normalized'].value_counts().items():
        print(f"  {label}: {count}")
    print()

    # Run debate
    results = []
    for idx, row in tqdm(df.iterrows(), total=len(df), desc="V6 Debate"):
        context = row.get('context', '')
        prompt = row.get('prompt', '')
        response = row.get('response', '')
        true_label = row['label_normalized']

        a1, a2, a3, final = debate_prediction_v6(
            model, tokenizer, context, prompt, response,
            max_new_tokens, temperature
        )

        results.append({
            'id': idx,
            'context': context,
            'prompt': prompt,
            'response': response,
            'agent1_argument': a1,
            'agent2_argument': a2,
            'agent3_decision': a3,
            'predicted_label': final,
            'ground_truth': true_label,
            'correct': final == true_label
        })

    results_df = pd.DataFrame(results)
    predictions = results_df['predicted_label'].tolist()
    ground_truth = results_df['ground_truth'].tolist()

    print("\n" + "="*70)
    print("V6 RESULTS")
    print("="*70 + "\n")

    other_count = (results_df['predicted_label'] == 'other').sum()
    print(f"'other': {other_count} / {len(results_df)} ({other_count/len(results_df)*100:.1f}%)\n")

    accuracy = accuracy_score(ground_truth, predictions)
    print(f"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\n")

    labels = ['no', 'intrinsic', 'extrinsic']
    precision, recall, f1, support = precision_recall_fscore_support(
        ground_truth, predictions, labels=labels, average=None, zero_division=0
    )

    print("Per-class:")
    print(f"{'Class':<15} {'Precision':<12} {'Recall':<12} {'F1':<12} {'Support':<10}")
    print("-" * 70)
    for i, label in enumerate(labels):
        print(f"{label:<15} {precision[i]:<12.4f} {recall[i]:<12.4f} {f1[i]:<12.4f} {support[i]:<10}")

    macro_p, macro_r, macro_f1, _ = precision_recall_fscore_support(
        ground_truth, predictions, labels=labels, average='macro', zero_division=0
    )

    print("-" * 70)
    print(f"{'Macro Avg':<15} {macro_p:<12.4f} {macro_r:<12.4f} {macro_f1:<12.4f}")
    print()
    print(f"ğŸ¯ Macro-F1: {macro_f1:.4f}")
    print(f"ğŸ¯ Accuracy: {accuracy:.4f}")
    print()

    cm = confusion_matrix(ground_truth, predictions, labels=labels)
    print("Confusion Matrix:")
    print(f"{'':>15} " + " ".join([f"{l:>12}" for l in labels]))
    for i, label in enumerate(labels):
        print(f"{label:>15} " + " ".join([f"{cm[i][j]:>12}" for j in range(len(labels))]))
    print()

    # Save
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    results_df.to_csv(output_path / "debate_detailed_results.csv", index=False)

    metrics = {
        "approach": "multi_agent_debate_v6_improved",
        "num_samples": len(df),
        "other_predictions": int(other_count),
        "accuracy": float(accuracy),
        "macro_f1": float(macro_f1),
        "per_class_metrics": {
            label: {"precision": float(precision[i]), "recall": float(recall[i]),
                   "f1": float(f1[i]), "support": int(support[i])}
            for i, label in enumerate(labels)
        },
        "confusion_matrix": cm.tolist()
    }

    with open(output_path / "debate_metrics.json", 'w') as f:
        json.dump(metrics, f, indent=2)

    print(f"âœ“ Results saved to: {output_dir}")
    print(f"\n{'='*70}")
    print("V6 COMPLETE!")
    print(f"{'='*70}\n")

    return metrics


def main():
    parser = argparse.ArgumentParser(description="Multi-Agent Debate V6 Improved")
    parser.add_argument("--model-path", type=str, default="merged_model")
    parser.add_argument("--test-csv", type=str, default="example-training/data/test.csv")
    parser.add_argument("--output-dir", type=str, default="debate_v6_results")
    parser.add_argument("--max-samples", type=int, default=100)
    parser.add_argument("--max-new-tokens", type=int, default=300)
    parser.add_argument("--temperature", type=float, default=0.15)

    args = parser.parse_args()

    try:
        evaluate_multi_agent_debate_v6(
            model_path=args.model_path,
            test_csv=args.test_csv,
            output_dir=args.output_dir,
            max_samples=args.max_samples,
            max_new_tokens=args.max_new_tokens,
            temperature=args.temperature,
        )
        print("\nâœ“ V6 completed!")
    except Exception as e:
        print(f"\nâœ— Error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()

